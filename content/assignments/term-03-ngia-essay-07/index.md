---
author: ["Shweata N. Hegde"]
title: "Term 03 | The New Geography of Information Age | Extension Notes 06: Is Censorship the Right Way to Go? Science Communication Perspective" 
date: "2024-11-30"
description: ""
tags: ["assignments", "term-03"]
ShowToc: true
---
Given our conversation in class about the complex issue of censorship on social media, I explored the role of censorship in science communication. At first glance, one might argue that removing non-factual content, such as "vaccines cause autism" and "plant X has proven to cure Y disease," might be the best option to prevent its further spread. However, the problem is that non-factual content is complicated and takes many forms—misinformation, disinformation, and conspiracy theories—all of which require different approaches to address.

For example, if someone claims that vaccines cause autism, it is important to recognize that they are basing their argument on a scientific paper that was once published and later retracted. This brings me to my first point: contrary to society’s perception of science as a collection of facts, the power of science lies in its uncertainty. When researchers publish a finding, they attach a specific uncertainty to it. This means that when presented with sufficient evidence, that finding can be refuted. For an observer, science correcting itself to make progress might sound confusing; what was once considered a fact may no longer be a fact. Therefore, improving scientific literacy should be at the heart of combating misinformation caused by a lack of understanding of scientific processes. Censorship does not address this.

Censorship also leads to another problem: it pushes misinformation into “harder-to-reach corners of the internet.” My preliminary research on vaccine misinformation on YouTube suggests that non-factual anti-vaccine content has become harder to find compared to a few years ago. But when you dig deeper into the comments, you find anti-vaccine content. Therefore, censorship is not directly leading to the anti-vaccine community becoming smaller; they are still present, but they no longer immediately appear in mainstream social media search results. In some sense, this is good because there is a reduced chance of a user stumbling upon a misinformation post by chance. However, this is my second point: it also makes it harder to address the issue of misinformation itself, as it continues to propagate within its echo chambers.

Disinformation and conspiracy theories, such as “the Earth is flat,” “climate change is not real,” and “5G causes the spread of coronavirus,” are among the most complex types of non-factual content to deal with. In these cases, there are people at extremes, and what gets censored directly influences the discourse about the issue.

What should we be doing to combat non-factual information, then? Researchers suggest that there should be open, transparent discussions, which need to be fostered by social media platforms. Fact-checking, done both at individual and organizational levels, plays a crucial role in carefully debunking arguments and thereby ensuring a balanced conversation. There also needs to be trust built between scientific organizations and citizens. Algorithms, too, can be modified in such a manner that misinformation once flagged appears less often on people’s feeds, thereby limiting its reach. Circling back to the process of science, conversations on social media about science should also involve a back-and-forth, where users use the latest evidence while making claims.

## Works Cited
1. “Royal Society Cautions against Censorship of Scientific Misinformation Online | Royal Society.” Royalsociety.org, 19 Jan. 2022, royalsociety.org/news/2022/01/scientific-misinformation-report/.
2. Schraer, Rachel. “Should Bad Science Be Censored on Social Media?” BBC News, 19 Jan. 2022, www.bbc.com/news/technology-60036861.
